{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f516d98-97e8-4d7b-99be-61e9100f1998",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3812318127.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mhttps://github.com/analyticswithadam/Python/blob/main/Pull_all_Comments_and_Replies_for_YouTube_Playlists.ipynb\u001b[39m\n          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# mastermind\n",
    "# https://github.com/analyticswithadam/Python/blob/main/Pull_all_Comments_and_Replies_for_YouTube_Playlists.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27f6d584-092c-468d-96ec-66c10a186c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da8b427a-1295-41a7-b5f0-f088743c32ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter your YouTube API key:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    }
   ],
   "source": [
    "api_key = getpass.getpass('Please enter your YouTube API key: ')\n",
    "playlist_ids = ['PL3-OIwNPoC3JFEvZP_nSMPrib8viH2KX-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "269fda0a-e234-4359-836d-ecefd7a987d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the YouTube client\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68d9f493-4433-49a0-be5b-4654c4f692fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function to pull all comments from a youtube playlist. \n",
    "# Only include the text following the signin the playlists url.\n",
    "\n",
    "\n",
    "def get_all_video_ids_from_playlists(youtube, playlist_ids):\n",
    "    all_videos = []  # Initialize a single list to hold all video IDs\n",
    "\n",
    "    for playlist_id in playlist_ids:\n",
    "        next_page_token = None\n",
    "\n",
    "        # Fetch videos from the current playlist\n",
    "        while True:\n",
    "            playlist_request = youtube.playlistItems().list(\n",
    "                part='contentDetails',\n",
    "                playlistId=playlist_id,\n",
    "                maxResults=50,\n",
    "                pageToken=next_page_token)\n",
    "            playlist_response = playlist_request.execute()\n",
    "\n",
    "            all_videos += [item['contentDetails']['videoId'] for item in playlist_response['items']]\n",
    "\n",
    "            next_page_token = playlist_response.get('nextPageToken')\n",
    "\n",
    "            if next_page_token is None:\n",
    "                break\n",
    "\n",
    "    return all_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e736520e-ff3e-45f2-a91a-a82379c76f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET ALL COMMENTS!!!\n",
    "\n",
    "# Fetch all video IDs from the specified playlists\n",
    "video_ids = get_all_video_ids_from_playlists(youtube, playlist_ids)\n",
    "\n",
    "# Function to get replies for a specific comment\n",
    "def get_replies(youtube, parent_id, video_id):  # Added video_id as an argument\n",
    "    replies = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while True:\n",
    "        reply_request = youtube.comments().list(\n",
    "            part=\"snippet\",\n",
    "            parentId=parent_id,\n",
    "            textFormat=\"plainText\",\n",
    "            maxResults=100,\n",
    "            pageToken=next_page_token\n",
    "        )\n",
    "        reply_response = reply_request.execute()\n",
    "\n",
    "        for item in reply_response['items']:\n",
    "            comment = item['snippet']\n",
    "            replies.append({\n",
    "                'Timestamp': comment['publishedAt'],\n",
    "                'Username': comment['authorDisplayName'],\n",
    "                'VideoID': video_id,\n",
    "                'Comment': comment['textDisplay'],\n",
    "                'Date': comment['updatedAt'] if 'updatedAt' in comment else comment['publishedAt']\n",
    "            })\n",
    "\n",
    "        next_page_token = reply_response.get('nextPageToken')\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return replies\n",
    "\n",
    "# Function to get all comments (including replies) for a single video\n",
    "def get_comments_for_video(youtube, video_id):\n",
    "    all_comments = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while True:\n",
    "        comment_request = youtube.commentThreads().list(\n",
    "            part=\"snippet\",\n",
    "            videoId=video_id,\n",
    "            pageToken=next_page_token,\n",
    "            textFormat=\"plainText\",\n",
    "            maxResults=100\n",
    "        )\n",
    "        comment_response = comment_request.execute()\n",
    "\n",
    "        for item in comment_response['items']:\n",
    "            top_comment = item['snippet']['topLevelComment']['snippet']\n",
    "            all_comments.append({\n",
    "                'Timestamp': top_comment['publishedAt'],\n",
    "                'Username': top_comment['authorDisplayName'],\n",
    "                'VideoID': video_id,  # Directly using video_id from function parameter\n",
    "                'Comment': top_comment['textDisplay'],\n",
    "                'Date': top_comment['updatedAt'] if 'updatedAt' in top_comment else top_comment['publishedAt']\n",
    "            })\n",
    "\n",
    "            # # Fetch replies if there are any\n",
    "            # if item['snippet']['totalReplyCount'] > 0:\n",
    "            #     all_comments.extend(get_replies(youtube, item['snippet']['topLevelComment']['id'], video_id))\n",
    "\n",
    "        next_page_token = comment_response.get('nextPageToken')\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return all_comments\n",
    "\n",
    "# List to hold all comments from all videos\n",
    "all_comments = []\n",
    "\n",
    "\n",
    "for video_id in video_ids:\n",
    "    video_comments = get_comments_for_video(youtube, video_id)\n",
    "    all_comments.extend(video_comments)\n",
    "\n",
    "# Create DataFrame\n",
    "comments_df = pd.DataFrame(all_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d8fb80b-348f-4b20-8a80-7b1ba85aafb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df.to_csv('Rep_debate_comments.csv', index=False)\n",
    "# # TO APPEND TO CSV:\n",
    "# # new_df.to_csv('existing_data.csv', mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "653822f9-0bd8-4fca-89c7-3e389b0bfea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Rep_debate_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bfb3c41-cf6a-428e-a31f-815e1caae3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11005, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54e6f6c7-4a7e-4981-a04e-7a6efec30e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('Dem_debate_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa17e4ab-5bda-4f1e-8eb5-7514656d4936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94219, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1dde11-2d4a-42b7-86e6-5cc4d36fdf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORKED GREAT FOR COMMENTS FROM ONE VIDEO\n",
    "\n",
    "\n",
    "def getcomments(video):\n",
    "  request = youtube.commentThreads().list(\n",
    "      part=\"snippet\",\n",
    "      videoId=video,\n",
    "      maxResults=100\n",
    "  )\n",
    "\n",
    "  comments = []\n",
    "\n",
    "  # Execute the request.\n",
    "  response = request.execute()\n",
    "\n",
    "  # Get the comments from the response.\n",
    "  for item in response['items']:\n",
    "      comment = item['snippet']['topLevelComment']['snippet']\n",
    "      public = item['snippet']['isPublic']\n",
    "      comments.append([\n",
    "          comment['authorDisplayName'],\n",
    "          comment['publishedAt'],\n",
    "          comment['likeCount'],\n",
    "          comment['textOriginal'],\n",
    "          comment['videoId'],\n",
    "          public\n",
    "      ])\n",
    "\n",
    "  while (1 == 1):\n",
    "    try:\n",
    "     nextPageToken = response['nextPageToken']\n",
    "    except KeyError:\n",
    "     break\n",
    "    nextPageToken = response['nextPageToken']\n",
    "    # Create a new request object with the next page token.\n",
    "    nextRequest = youtube.commentThreads().list(part=\"snippet\", videoId=video, maxResults=100, pageToken=nextPageToken)\n",
    "    # Execute the next request.\n",
    "    response = nextRequest.execute()\n",
    "    # Get the comments from the next response.\n",
    "    for item in response['items']:\n",
    "      comment = item['snippet']['topLevelComment']['snippet']\n",
    "      public = item['snippet']['isPublic']\n",
    "      comments.append([\n",
    "          comment['authorDisplayName'],\n",
    "          comment['publishedAt'],\n",
    "          comment['likeCount'],\n",
    "          comment['textOriginal'],\n",
    "          comment['videoId'],\n",
    "          public\n",
    "      ])\n",
    "\n",
    "  df2 = pd.DataFrame(comments, columns=['author', 'updated_at', 'like_count', 'text','video_id','public'])\n",
    "  return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49055fda-e951-4a6d-b652-58894da69086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5165fc44-5f81-4d29-ae65-ce189280742d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>published_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>like_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@michelecruz6365</td>\n",
       "      <td>2024-12-07T16:51:50Z</td>\n",
       "      <td>2024-12-07T16:51:50Z</td>\n",
       "      <td>1</td>\n",
       "      <td>The one thing i so admire about President Trum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@MyLifeTheStruggle1</td>\n",
       "      <td>2024-11-10T03:41:11Z</td>\n",
       "      <td>2024-11-10T03:41:11Z</td>\n",
       "      <td>0</td>\n",
       "      <td>2024 304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@alfredm5400</td>\n",
       "      <td>2024-11-03T23:23:39Z</td>\n",
       "      <td>2024-11-03T23:23:39Z</td>\n",
       "      <td>0</td>\n",
       "      <td>trump 2024 üéâ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@MarcosAntonio-z8y9h</td>\n",
       "      <td>2024-10-22T20:48:18Z</td>\n",
       "      <td>2024-10-22T20:48:18Z</td>\n",
       "      <td>0</td>\n",
       "      <td>@Buenas noches fuerza brutalidad hoy coneza el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@langtran-nn2jq</td>\n",
       "      <td>2024-10-22T20:43:31Z</td>\n",
       "      <td>2024-10-22T20:43:31Z</td>\n",
       "      <td>0</td>\n",
       "      <td>‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@MarcosAntonio-z8y9h</td>\n",
       "      <td>2024-10-22T20:40:52Z</td>\n",
       "      <td>2024-10-22T20:40:52Z</td>\n",
       "      <td>0</td>\n",
       "      <td>@Thank you God for forgive Ness though the pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@mdjahangirhossain-l2d</td>\n",
       "      <td>2024-10-22T09:06:05Z</td>\n",
       "      <td>2024-10-22T09:06:05Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Well done ‚ù§‚ù§‚ù§‚ù§‚ù§ &lt;a href=\"https://www.youtube.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@marienzasokau8127</td>\n",
       "      <td>2024-10-22T08:57:40Z</td>\n",
       "      <td>2024-10-22T08:57:40Z</td>\n",
       "      <td>0</td>\n",
       "      <td>It is now October, the twenty second day of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@Juana.V.V</td>\n",
       "      <td>2024-10-16T09:25:09Z</td>\n",
       "      <td>2024-10-16T09:25:09Z</td>\n",
       "      <td>0</td>\n",
       "      <td>u  s   e  presidente   republicano    presiden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@Eugenio-c3o</td>\n",
       "      <td>2024-10-14T10:05:58Z</td>\n",
       "      <td>2024-10-14T10:05:58Z</td>\n",
       "      <td>0</td>\n",
       "      <td>I&amp;#39;M PALAUAN FROM PALAU ISLAND LOCATED IN W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   author          published_at            updated_at  \\\n",
       "0        @michelecruz6365  2024-12-07T16:51:50Z  2024-12-07T16:51:50Z   \n",
       "1     @MyLifeTheStruggle1  2024-11-10T03:41:11Z  2024-11-10T03:41:11Z   \n",
       "2            @alfredm5400  2024-11-03T23:23:39Z  2024-11-03T23:23:39Z   \n",
       "3    @MarcosAntonio-z8y9h  2024-10-22T20:48:18Z  2024-10-22T20:48:18Z   \n",
       "4         @langtran-nn2jq  2024-10-22T20:43:31Z  2024-10-22T20:43:31Z   \n",
       "5    @MarcosAntonio-z8y9h  2024-10-22T20:40:52Z  2024-10-22T20:40:52Z   \n",
       "6  @mdjahangirhossain-l2d  2024-10-22T09:06:05Z  2024-10-22T09:06:05Z   \n",
       "7      @marienzasokau8127  2024-10-22T08:57:40Z  2024-10-22T08:57:40Z   \n",
       "8              @Juana.V.V  2024-10-16T09:25:09Z  2024-10-16T09:25:09Z   \n",
       "9            @Eugenio-c3o  2024-10-14T10:05:58Z  2024-10-14T10:05:58Z   \n",
       "\n",
       "   like_count                                               text  \n",
       "0           1  The one thing i so admire about President Trum...  \n",
       "1           0                                           2024 304  \n",
       "2           0                                       trump 2024 üéâ  \n",
       "3           0  @Buenas noches fuerza brutalidad hoy coneza el...  \n",
       "4           0                                             ‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§  \n",
       "5           0  @Thank you God for forgive Ness though the pre...  \n",
       "6           0  Well done ‚ù§‚ù§‚ù§‚ù§‚ù§ <a href=\"https://www.youtube.c...  \n",
       "7           0  It is now October, the twenty second day of th...  \n",
       "8           0  u  s   e  presidente   republicano    presiden...  \n",
       "9           0  I&#39;M PALAUAN FROM PALAU ISLAND LOCATED IN W...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# request = youtube.commentThreads().list(\n",
    "#     part=\"snippet\",\n",
    "#     videoId=\"ltNVyvK8Paw\",\n",
    "#     maxResults=1000\n",
    "# )\n",
    "# response = request.execute()\n",
    "\n",
    "# comments = []\n",
    "\n",
    "# for item in response['items']:\n",
    "#     comment = item['snippet']['topLevelComment']['snippet']\n",
    "#     comments.append([\n",
    "#         comment['authorDisplayName'],\n",
    "#         comment['publishedAt'],\n",
    "#         comment['updatedAt'],\n",
    "#         comment['likeCount'],\n",
    "#         comment['textDisplay']\n",
    "#     ])\n",
    "\n",
    "\n",
    "# # TO APPEND TO CSV:\n",
    "# # new_df.to_csv('existing_data.csv', mode='a', index=False, header=False)\n",
    "# df = pd.DataFrame(comments, columns=['author', 'published_at', 'updated_at', 'like_count', 'text'])\n",
    "\n",
    "# df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14ad558b-0ad3-4227-bb3c-79d9b02e961f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df.to_csv('existing_data.csv', mode='a', index=False, header=False)\n",
    "\n",
    "\n",
    "df.to_csv('trump_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bb2fcb-6be3-4162-9d9f-eb0d20dd6b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export whole dataset to the local machine as CSV File\n",
    "# csv_file = 'comments_data.csv'  # Name your file\n",
    "# comments_df.to_csv(csv_file, index=False)\n",
    "\n",
    "# from google.colab import files\n",
    "\n",
    "# # Trigger a download to your local machine\n",
    "# files.download(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f534deca-b5a2-4444-bc47-d8e46f87effd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to get replies for a specific comment\n",
    "# def get_replies(youtube, parent_id, video_id):  # Added video_id as an argument\n",
    "#     replies = []\n",
    "#     next_page_token = None\n",
    "\n",
    "#     while True:\n",
    "#         reply_request = youtube.comments().list(\n",
    "#             part=\"snippet\",\n",
    "#             parentId=parent_id,\n",
    "#             textFormat=\"plainText\",\n",
    "#             maxResults=100,\n",
    "#             pageToken=next_page_token\n",
    "#         )\n",
    "#         reply_response = reply_request.execute()\n",
    "\n",
    "#         for item in reply_response['items']:\n",
    "#             comment = item['snippet']\n",
    "#             replies.append({\n",
    "#                 'Timestamp': comment['publishedAt'],\n",
    "#                 'Username': comment['authorDisplayName'],\n",
    "#                 'VideoID': video_id,\n",
    "#                 'Comment': comment['textDisplay'],\n",
    "#                 'Date': comment['updatedAt'] if 'updatedAt' in comment else comment['publishedAt']\n",
    "#             })\n",
    "\n",
    "#         next_page_token = reply_response.get('nextPageToken')\n",
    "#         if not next_page_token:\n",
    "#             break\n",
    "\n",
    "#     return replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e5d5f7-d877-44f8-84e2-1ef71be201a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to get all comments (including replies) for a single video\n",
    "# def get_comments_for_video(youtube, video_id):\n",
    "#     all_comments = []\n",
    "#     next_page_token = None\n",
    "\n",
    "#     while True:\n",
    "#         comment_request = youtube.commentThreads().list(\n",
    "#             part=\"snippet\",\n",
    "#             videoId=video_id,\n",
    "#             pageToken=next_page_token,\n",
    "#             textFormat=\"plainText\",\n",
    "#             maxResults=100\n",
    "#         )\n",
    "#         comment_response = comment_request.execute()\n",
    "\n",
    "#         for item in comment_response['items']:\n",
    "#             top_comment = item['snippet']['topLevelComment']['snippet']\n",
    "#             all_comments.append({\n",
    "#                 'Timestamp': top_comment['publishedAt'],\n",
    "#                 'Username': top_comment['authorDisplayName'],\n",
    "#                 'VideoID': video_id,  # Directly using video_id from function parameter\n",
    "#                 'Comment': top_comment['textDisplay'],\n",
    "#                 'Date': top_comment['updatedAt'] if 'updatedAt' in top_comment else top_comment['publishedAt']\n",
    "#             })\n",
    "\n",
    "#             # Fetch replies if there are any\n",
    "#             if item['snippet']['totalReplyCount'] > 0:\n",
    "#                 all_comments.extend(get_replies(youtube, item['snippet']['topLevelComment']['id'], video_id))\n",
    "\n",
    "#         next_page_token = comment_response.get('nextPageToken')\n",
    "#         if not next_page_token:\n",
    "#             break\n",
    "\n",
    "#     return all_comments\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
